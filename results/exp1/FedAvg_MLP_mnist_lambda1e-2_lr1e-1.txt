# Configuration:

dataset name: mnist
model name: softmax classification with MLP
num_clients: 100
participation_rate: 0.3
num_classes: 10
numLocalEpochs: 10
learning_rate: 0.1
lambda: 0.01
mu: 0.0
num_classes: 10
# Results:

round,obj,test
1,1.2542019375006186,0.8205
2,0.9605193110176403,0.8675
3,0.869728166964674,0.8832
4,0.8188244698439199,0.8925
5,0.781481808958146,0.8979
6,0.7518108078400588,0.9016
7,0.7275981809831384,0.9042
8,0.7068180969762353,0.9073
9,0.6890095112575202,0.909
10,0.6734614088689415,0.9103
11,0.6595398033964337,0.9119
12,0.6472136509497118,0.9118
13,0.6355901838558393,0.914
14,0.6259181578760333,0.9157
15,0.6164201204637252,0.9153
16,0.6084278657596163,0.9162
17,0.6012662539465631,0.9175
18,0.595128366373081,0.9164
19,0.5892709681640813,0.9178
20,0.5834946113211495,0.9177
21,0.5789006878611649,0.9179
22,0.5748419464309851,0.9186
23,0.5703263274502284,0.9186
24,0.5664410376684055,0.9195
25,0.5634866749750946,0.9196
26,0.5605009655913397,0.9207
27,0.5574363451162215,0.9197
28,0.5547568335952121,0.9203
29,0.5527976591108638,0.9202
30,0.5507907342114002,0.9211
31,0.5486265267040825,0.9218
32,0.5470791555756712,0.9222
33,0.545094049570739,0.9224
34,0.5432862574246404,0.9226
35,0.5418600196157937,0.9232
36,0.5405329896178678,0.9232
37,0.5397226504435417,0.9228
38,0.5382716689788409,0.9238
39,0.5377682929237775,0.9231
40,0.5362686026235032,0.9235
41,0.5358135285014238,0.9235
42,0.5345151736797612,0.9251
43,0.5337021823873147,0.9253
44,0.5328620522367261,0.9239
45,0.5325426044278737,0.9253
46,0.5316431603682519,0.9251
47,0.5310065192789316,0.9258
48,0.5306628257744741,0.9256
49,0.5303003275442535,0.9254
50,0.5297318355999721,0.925
51,0.5290093004450825,0.9259
52,0.5288836185001111,0.925
53,0.5280436799619622,0.9263
54,0.5276457624615567,0.9262
55,0.5274809752453778,0.9261
56,0.5278127816648129,0.9249
57,0.5271531500537221,0.9249
58,0.5262146986709649,0.9259
59,0.5261575436136237,0.9262
60,0.5261397688609212,0.9268
61,0.5257494445004222,0.9254
62,0.5260749241243946,0.9264
63,0.5251884786612208,0.9271
64,0.5245442049492526,0.9271
65,0.5243335265032518,0.9275
66,0.5242660055187941,0.9292
67,0.5237971026182582,0.9283
68,0.5240039527853974,0.9285
69,0.5234237974626479,0.928
70,0.5230454902781556,0.9279
71,0.52319941875053,0.9276
72,0.5230469299272948,0.9278
73,0.5226582689008642,0.9273
74,0.5225953798695189,0.928
75,0.5226564836220889,0.9275
76,0.5222300614460577,0.9287
77,0.5222212883154553,0.9285
78,0.5216881259863811,0.9287
79,0.5219332517375866,0.9275
80,0.5216673496208416,0.9283
81,0.521645408949163,0.9291
82,0.5214815397444794,0.9285
83,0.5214191071788409,0.9286
84,0.5207451667544869,0.9293
85,0.5207808493795278,0.9283
86,0.5206195767984723,0.9284
87,0.5204509045754458,0.9286
88,0.5205597873582207,0.929
89,0.5200531924698667,0.9295
90,0.519911289663557,0.9292
91,0.5202382154356523,0.9289
92,0.5198728392598285,0.9289
93,0.5197000206747538,0.9289
94,0.5194968842494708,0.9294
95,0.5198555862745328,0.9296
96,0.5195651423974196,0.9301
97,0.5193997777845233,0.9305
98,0.5193963055388204,0.9291
99,0.51974095785948,0.9287
100,0.5191185531895224,0.9286
